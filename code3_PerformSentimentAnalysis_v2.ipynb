{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4e62e0",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "To perform sentiment analysis, we used nltk, specifically the SentimentIntensityAnalyzer class and the word_tokenize function. We loaded the CSV file containing the tweets using the csv module. To be able to analyze the sentiment in the tweets, we tokenized the tweets using the word_tokenize function from nltk.tokenize. This function breaks the sentence into individual words, which allows the model to work with each word independently. We then created an instance of the SentimentIntensityAnalyzer class from nltk.sentiment. This class contains a pre-built lexicon called the VADER lexicon, which is specifically attuned to sentiments expressed in social media. The lexicon contains words and their associated sentiment scores, which are based on human-generated scores. It also contains slang and emoticons that are commonly used in social media and are not present in traditional sentiment analysis lexicons. We used the SentimentIntensityAnalyzer object to perform sentiment analysis on each tokenized tweet. We called the polarity_scores method on the object and passed in the tokenized tweet. This method returns a dictionary containing the sentiment scores for the text, including 'neg', 'neu', 'pos' and 'compound'. Then, we added the sentiment analysis results (neg, neu, pos, and compound) as new columns to the data variable. We used a loop to go through each tweet and extract the sentiment scores and add them to the data variable as new columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50faa9",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements, known as tokens. Tokenization is an important step in natural language processing (NLP) because it allows the model to work with individual words or phrases, rather than the entire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254c477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sarai/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "#The lexicon contains words and their associated sentiment scores, which are based on human-generated scores. \n",
    "#lexico from social media\n",
    "nltk.download('vader_lexicon')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c1fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(filepath):\n",
    "    \"\"\"\n",
    "    Read the text file located at the given file path and return its content as a list of strings.\n",
    "\n",
    "    Parameters:\n",
    "    filepath: A string representing the file path of the text file to read.\n",
    "\n",
    "    Returns:\n",
    "    data: A list of strings, where each string in the list represents a line in the text file.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_text_file(filepath, data):\n",
    "    \"\"\"\n",
    "    Write the given list of strings to a text file located at the given file path.\n",
    "\n",
    "    Parameters:\n",
    "    filepath: A string representing the file path of the text file to write.\n",
    "    data: A list of strings, where each string in the list should represent a line in the text file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.writelines(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04e854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on each line of text in the given list using the VADER sentiment analysis tool.\n",
    "    For each line of text, the function appends the sentiment analysis scores to the end of the line as tab-separated values.\n",
    "    Returns a new list of strings with the updated lines of text.\n",
    "    \n",
    "    Parameters:\n",
    "    data: A list of strings representing each line of text to be analyzed.\n",
    "    \n",
    "    Return: \n",
    "    A new list of strings with the updated lines of text.\n",
    "    \"\"\"\n",
    "    # Create a SentimentIntensityAnalyzer object from the nltk package\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    new_data = []\n",
    "    # Loop through each line of text in the input list\n",
    "    for line in data:\n",
    "        # Perform sentiment analysis on the line using the SentimentIntensityAnalyzer object\n",
    "        sentiment = sia.polarity_scores(line)\n",
    "        # Append the sentiment analysis scores to the end of the line as tab-separated values\n",
    "        new_line = line.strip() + f\"\\t{sentiment['neg']}\\t{sentiment['neu']}\\t{sentiment['pos']}\\t{sentiment['compound']}\\n\"\n",
    "        # Append the updated line of text to the output list\n",
    "        new_data.append(new_line)\n",
    "    # Return the list of updated lines of text\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82d97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_files(directory):\n",
    "    \"\"\"\n",
    "    Process all text files in the given directory.\n",
    "    Each text file should contain a line of text in each row.\n",
    "    The function performs sentiment analysis on each line of text, and writes the updated text back to the same file.\n",
    "    \n",
    "    Parameters:\n",
    "    directory: The directory containing the text files to be processed.\n",
    "    \n",
    "    Return:\n",
    "    Add the sentyment analysis tothe txt files\n",
    "    \"\"\"\n",
    "    # Get a list of all text files in the directory\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "    # Loop through each file and process its contents\n",
    "    for file in files:\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(directory, file)\n",
    "\n",
    "        # Read the data from the text file\n",
    "        data = read_text_file(filepath)\n",
    "\n",
    "        # Perform sentiment analysis on the data\n",
    "        data_with_sentiment = add_sentiment_analysis(data)\n",
    "\n",
    "        # Write the updated data back to the text file\n",
    "        write_text_file(filepath, data_with_sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2de30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the functions to add the sentyment analysis to our data\n",
    "#news\n",
    "process_text_files(\"/Users/sarai/Documents/DataAnalytics/_PROJECT/data/feb1March19/\")\n",
    "#ceos\n",
    "process_text_files(\"/Users/sarai/Documents/DataAnalytics/_PROJECT/data/feb1March19/ceos/\")\n",
    "#companies\n",
    "process_text_files(\"/Users/sarai/Documents/DataAnalytics/_PROJECT/data/feb1March19/companies/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3c41af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors\n",
    "#process_text_files(\"/Users/sarai/Documents/DataAnalytics/_PROJECT/data/feb1March1/ceos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca09a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
